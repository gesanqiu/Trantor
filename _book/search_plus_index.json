{"./":{"url":"./","title":"Introduction","keywords":"","body":"Introduction Something represents my growth. Update log 2021.02.28--First commit 2021.03.06--Update pinctrl&gpio 2021.03.21--Update ION buffer 2021.04.11--Update Gitbook Tutorial 2021.04.28--Update getopt_long() "},"pinctrl/pinctrl_gpio.html":{"url":"pinctrl/pinctrl_gpio.html","title":"Pinctrl & GPIO","keywords":"","body":" Pinctrl子系统 GPIO子系统 两者的交互 Pinctrl Subsystem 与 GPIO Subsystem的交互 Pinctrl子系统 开发人员可以针对一款SOC设计多块target board，每块target board可以有不同的用途，但一款SOC提供的引脚资源是有限的，因此引脚的复用对于拓展SOC功能有重要意义，基于此Pinctrl子系统被设计出来，其主要目的在于： 管理系统中所有可以控制的引脚 引脚的复用 单个引脚的function 多个引脚组成pin group实现特定的功能 对应设备所需引脚的电器特性 GPIO子系统 GPIO作为嵌入式领域最基础的部分，我想大部分嵌入式工程师的入门都是从配置GPIO引脚，改变GPIO电平开始的。gpio子系统帮助我们管理整个系统gpio的使用情况，同时内核通过./drivers/gpio/gpiolib.c对外提供了一系列操控GPIO资源的接口。 两者的交互 从逻辑上来说，GPIO是Pin的一种function，因此GPIO Subsystem应该是Pinctrl Subsystem的client，基于pinctrl subsystem提供的功能，处理GPIO有关的逻辑，作为软件工程师我们期待的硬件设计应该如下图： GPIO的HW block应该和其他功能复用的block是对等关系的，它们共同输入到一个复用器block，这个block的寄存器控制哪一个功能电路目前是active的。pin configuration是全局的，不论哪种功能是active的，都可以针对pin进行电气特性的设定。这样的架构下，上图中上边的三个block是完全独立的HW block，其控制寄存器在SOC datasheet中应该是分成三个章节描述，同时，这些block的寄存器应该分别处于不同的地址区间。 但是在实际的设计中，我们知道Pinctrl Driver给GPIO Driver提供了一系列接口，因此SOC设计框架图如下： 即Pinctrl和GPIO两个子系统之间有一定的耦合，反映在硬件上就是两者的寄存器占据了一个memory range。 这么设计的原因我目前还没有清晰的理解，可能需要我接着看GPIO Subsystem的源码才能弄清楚，但是有两个思路： 历史原因：在早期SOC Pin脚不多的时候GPIO子系统就已经存在了，后来由于版本迭代加入了Pinctrl子系统，并且由于受到其复用设计的影响，最终决定把GPIO作为Pinctrl的一个bake-end加进来； 第二就是蜗窝科技在其文章1中提到这样一个例子： 假设某一个gpio chip只包括2个gpio，这两个gpio分别和uart进行功能复用。 如果这两个管脚是同时控制的，要么是gpio，要么是uart，就很好处理了，按照pinctrl subsystem的精神，抽象出两个function：gpio和uart，gpio chip在使用gpio功能的时候，调用pinctrl set state，将它们切换为gpio即可。 但是，如果这两个gpio可以分开控制（很多硬件都是这样的设计的），麻烦就出现了，每个gpio要单独抽象为一个function，因此我们可以抽象出3个function：gpio1、gpio2和uart。 然后考虑一下一个包含32个gpio的chip（一般硬件的gpio bank都是32个），如果它们都可以单独控制，则会出现32个function。而系统又不止有一个chip，灾难就发生了，我们的device tree文件将会被一坨坨的gpio functions撑爆！ 可能和文章发表日期有关，这个例子我觉得有些晦涩，因为据同事的说法只有早期需要自己手动对每个function进行配置的时候才会发生这种情况，目前我基于高通的平台做开发时，Pinctrl的配置已经变得非常简单，高通有自己的总线设计（Qualcomm Universal Peripheral v3 Serial Engine， QUP v3 SE），对SOC的Pin事先做了详细的configure和function的抽象，开发人员只需要按照datasheet配置即可。 以下是我对这个例子的一些理解： function需要自己根据datasheet去做关于pin脚读取寄存器的配置，假设我们把一个function理解成一个配置文件。 基于第一种框架设计，GPIO Block和SPI、I2C、UART等功能复用处于同一层次。 两个pin脚作为gpio复用可以同时控制的情况很好理解，要么是gpio，要么是uart，上层只需要带着指定的复用function配置文件交给Multiplexer即可同时完成对这两个引脚的功能选择。 当gpio chip下的gpio可以分开控制的时候，由于每个gpio都可以实现不同的IO功能，它们function的属性有所区别，各个gpio的function配置没法写在一起，因此每个gpio都得抽象出一个各自的function配置文件，因此在配置引脚的时候就会出现GPIO function撑爆设备树的情况。 此外由于对每个gpio都单独做了配置，在不同平台之间做移植的时候，需要修改大量的配置信息。 例子解释完，再来说说pinctrl和gpio的耦合设计是如何解决这个问题的（由于我目前还没找到高通平台关于function配置的代码，所以以下都是未经论证的个人猜想，未来有了新的理解会继续更新）： 由于采用了耦合设计，pinctrl直接向gpio提供接口进行资源的控制，这样就跳过了Multiplexer选择复用功能的过程，而是在gpio申请pin脚的时候直接由pinctrl将该pin脚指定为gpio功能。当gpio driver需要使用某个管脚的时候，直接调用pinctrl_request_gpio，向pinctrl subsystem申请，pinctrl subsystem会维护一个gpio number到pin number的map，将gpio subsystem传来的gpio number转换为pin number之后，调用struct pinmux_ops中有关的回调函数即可。 即由于采用耦合设计——它们寄存器处于一个memory range，使得gpio这个function的配置可以由pinctrl直接实现，对上层就表现为不需要再额外详细配置gpio这个function，gpio driver只需要提供gpio number即可。 1. linux内核中的GPIO系统之（5）：gpio subsysem和pinctrl subsystem之间的耦合 ↩ "},"Device_Tree/设备树.html":{"url":"Device_Tree/设备树.html","title":"Device Tree","keywords":"","body":" 组成 结构 property DTS node结构 设备节点结构体 DTS示例 reg 引用 phandle引用 label引用 覆盖 1.同一层次的节点，后面的会覆盖前面的节点 2.直接引用方式覆盖（增加）节点属性 DTB DTB起始段 内存预留段 结构块 令牌 字符串块 DTB示例 设备树 设备树是一种描述硬件资源的数据结构。它通过bootloader将硬件资源传给内核，使得内核和硬件资源描述相对独立。 设备树的主要优势：对于同一SOC的不同主板，只需更换设备树文件.dtb即可实现不同主板的无差异支持，而无需更换内核文件。 组成 DTS（Device Tree Source）：dts文件是对Device Tree的描述，放置在内核的/arch/arm/boot/dts目录。一个dts文件对应一个ARM的machine。dts文件描述了一个板子的硬件资源。 DTC（Device Tree Compiler）：编译工具，可以将dts文件编译成dtb文件。 DTB（Device Tree Blob）：DTC将dts编译成dtb文件，bootloader在引导内核是，会预先读取dtb文件到内存进而由内核解析。 DTSI（Device Tree Source Include）：dts文件的头文件。由于一个SOC可能有多个不同的电路板，而每个电路板拥有一个 .dts。这些dts可能会存在许多共同部分，为了减少代码的冗余，设备树将这些共同部分提炼保存在.dtsi文件中，供不同的dts共同使用。 结构 / o device-tree |- name = \"device-tree\" |- model = \"MyBoardName\" |- compatible = \"MyBoardFamilyName\" |- #address-cells = |- #size-cells = |- linux,phandle = | o cpus | | - name = \"cpus\" | | - linux,phandle = | | - #address-cells = | | - #size-cells = | | | o PowerPC,970@0 | |- name = \"PowerPC,970\" | |- device_type = \"cpu\" | |- reg = | |- clock-frequency = | |- 64-bit | |- linux,phandle = | o memory@0 | |- name = \"memory\" | |- device_type = \"memory\" | |- reg = | |- linux,phandle = | o chosen |- name = \"chosen\" |- bootargs = \"root=/dev/sda2\" |- linux,phandle = device tree的基本单元是node，node组成了树状结构。 除了root node，每个node都只有一个parent，一个device tree文件中只能有一个root node 每个node包含了若干的来描述node 每个node使用node name来标识：node-name[@unit-address]（需要reg属性） 引用node需要使用full path property property的value可能为空 可能是一个u32、u64的数值，用<>表示例如cell在Device Tree中表示32bit的信息单位 可以是string或string list 可以是binary data，用[]表示 DTS node结构 [label:] node-name[@unit-address] { [properties definitions] [child nodes] } label为引用，node寻址为full path，在多层嵌套是引用不便，可以用label直接引用 @unit-address通常用于区分同一级别（不同级别设备节点名称可以相同，通过地址区分）名字相同的外设备（例如两块内存） child node可嵌套 设备节点结构体 struct device_node { const char *name; //设备name const char *type; //设备类型 phandle phandle; const char *full_name; //设备全称，包括父设备名 struct property *properties; //设备属性链表 struct property *deadprops; //removed properties struct device_node *parent; //指向父节点 struct device_node *child; //指向子节点 struct device_node *sibling; //指向兄弟节点 struct device_node *next; //相同设备类型的下一个节点 struct device_node *allnext; //next in list of all nodes struct proc_dir_entry *pde; //该节点对应的proc struct kref kref; unsigned long _flags; void *data; #if defined(CONFIG_SPARC) const char *path_component_name; unsigned int unique_id; struct of_irq_controller *irq_trans; #endif }; DTS示例 /dts-v1/; #include #include \"s5pv210.dtsi\" / { model = \"YIC System SMDKV210 based on S5PV210\"; compatible = \"yic,smdkv210\", \"samsung,s5pv210\"; chosen { bootargs = \"console=ttySAC2,115200n8 root=/dev/nfs nfsroot=192.168.0.101:/home/run/work/rootfs/rootfs_3.16.57 ip=192.1 68.0.20 init=/linuxrci earlyprintk\"; }; memory@30000000 { device_type = \"memory\"; reg = ; }; ethernet@88000000 { compatible = \"davicom,dm9000\"; reg = ; interrupt-parent = ; interrupts = ; local-mac-address = [00 00 de ad be ef]; davicom,no-eeprom; clocks = ; clock-names = \"sromc\"; }; key { empty_property; } }; model：设备制造商的描述，如果两块板子compatible相同就用model区分 compatible：一个由\"manufacture，model\"字符串组成的string list，系统根据model值查找drivers phandle：取值必须唯一，在其他dts中可以使用phandle的值来引用该节点 reg reg：描述设备在其父总线定义的地址空间中的地址，通常这意味着内存映射IO寄存器块的偏移量和长度 #address-cells：‘#’代表number，表示子节点的reg属性中使用多少个u32来描述地址 #size-cells：表示子节点的reg属性中使用多少个u32来描述地址长度 假设64位系统，如果physical memory分成两段，定义如下： RAM: starting address 0x0, length 0x80000000 (2GB) RAM: starting address 0x100000000, length 0x100000000 (4GB) 那么父节点#address-cells=，#size-cells，两端物理内存节点描述如下： //方法1： memory@0 { device_type = \"memory\"; reg = ; }; //方法2： memory@0 { device_type = \"memory\"; reg = ; }; memory@100000000 { device_type = \"memory\"; reg = ; }; 引用 phandle引用 pic@10000000 { phandle = ; interrupt-controller; }; another-device-node { interrupt-parent = ; // 使用phandle值为1来引用上述节点 }; 使用phandle引用需要确保设备树文件中phandle的值唯一 label引用 PIC: pic@10000000 { interrupt-controller; }; another-device-node { interrupt-parent = ; // 使用label来引用上述节点, // 使用lable时实际上也是使用phandle来引用, // 在编译dts文件为dtb文件时, 编译器dtc会在dtb中插入phandle属性 }; dtc在编译的时候会在使用label的节点中增加一个phandle的属性，增加一个唯一的value，并把使用它的位置替换为该value。 覆盖 1.同一层次的节点，后面的会覆盖前面的节点 memory@30000000 { device_type = \"memory\"; reg = ; }; memory@30000000 { reg = ; }; memory@30000000 { device_type = \"memory\"; reg = ; }; dtc编译之后reg会被覆盖为reg = ; 2.直接引用方式覆盖（增加）节点属性 //*.dtsi中的节点 xusbxti: oscillator@1 { compatible = \"fixed-clock\"; reg = ; clock-frequency = ; clock-output-names = \"xusbxti\"; #clock-cells = ; }; //引用上述dtsi中的节点 &xusbxti { clock-frequency = ; } 在编译过后节点的clock-frequency被替换成 DTB DTB起始段 struct fdt_header { uint32_t magic; uint32_t totalsize; uint32_t off_dt_struct; uint32_t off_dt_strings; uint32_t off_mem_rsvmap; uint32_t version; uint32_t last_comp_version; uint32_t boot_cpuid_phys; uint32_t size_dt_strings; uint32_t size_dt_struct; }; magic：魔数，此字段应包含值0xd00dfeed totalsize：此字段应包含device tree数据结构的总大小（以字节为单位），这个大小包含所有结构的各个部分：标题，内存预留块，结构块和字符串块，以及任何块之间或最终块之后的自由空间间隙 off_dt_struct：结构块的偏移量 off_dt_strings：字符串块的字节偏移量 off_mem_rsvmap：内存预留块的偏移量，这些保留内存不会进入内存管理系统 version：该dtb的版本 last_comp_version：兼容版本信息 boot_cpuid_phys：该字段应包含系统引导CPU的物理ID，它应该与device tree中该CPU节点的reg属性中给出的物理ID相同 size_dt_strings：此字段应包含device tree blob的字符串块部分的字节长度 size_dt_struct：此字段应包含device tree blob的结构块部分的字节长度 内存预留段 reserve memory描述符： struct fdt_reserve_entry { uint64_t address; uint64_t size; }; 结构块 描述设备本身的结构和内容，由一系列令牌组成，这些令牌被组织成线性树结构。 令牌 FDT_BEGIN_NODE(0x00000001)：标记节点的开始，后接节点的单元名称，该名称包括以空字符结尾的节点名字符串和单元地址（如果有），如果需要对齐就就填充0x00，然后是下一个令牌，可以是除了FDT_END之外的任意令牌 FDT_END_NODE(0x00000002)：标记节点的结束，接FDT_PROP以外的任意令牌 FDT_PROP(0x00000003)：节点属性令牌，首先是属性长度，可以为0字节表示空属性；然后是属性名在字符串块中的偏移量；接着属性值占属性长度个字节，如果需要对齐就填充0x00（对齐到32位），然后接除FDT_END以外的任意令牌 struct { uint32_t len; uint32_t nameoff; } FDT_NOP(0x00000004)：覆盖令牌，dtc不解析该令牌，直接跳到下一个令牌解析，因此在此令牌后的所有属性或节点描述都将失效，从树中移除。 FDT_END(0x00000009)：结构块的结束 字符串块 包含树中使用的所有属性名称的字符串，这些空终止字符串在本节中简单地连接在一起，并通过字符串块中的偏移量从结构块中引用。字符串块没有对齐约束，可能出现在device tree blob开头的任何偏移处。 DTB示例 /dts-v1/; /memreserve/ 0x4ff00000 0x100000; / { model = \"YIC System SMDKV210 based on S5PV210\"; compatible = \"yic,smdkv210\", \"samsung,s5pv210\"; #address-cells = ; #size-cells = ; chosen { bootargs = \"console=ttySAC2,115200n8 root=/dev/nfs nfsroot=192.168.0.101:/home/run/work/rootfs/\"; }; memory@30000000 { device_type = \"memory\"; reg = ; }; }; 编译后的.dtb文件信息如下： "},"GStreamer/GStreamer.html":{"url":"GStreamer/GStreamer.html","title":"Gstreamer","keywords":"","body":" 架构 Media Applications Core Framework Plugins GStreamer组件 Element 创建一个GstElement 箱柜bin 创建一个bin 常用操作 元件的状态 衬垫Pad Pad link Pad Capability Pad Capability for Filtering Ghost Pad 动态衬垫 Dynamic pads Bus Gstreamer数据消息交互 GStreamer 架构 Media Applications 应用层，包括gstreamer自带的工具（gst-inspect、gst-launch）以及基于gstreamer封装的库 Core Framework 上层应用所需的接口 Plugin的框架 Pipeline的框架 数据在各个Element间的传输及处理机制 多个媒体流间的同步（比如音视频同步） 其他各种所需的工具库 Plugins Protocols：负责各种协议的处理，file，http，rtsp等。 Sources：负责数据源的处理，alsa，v4l2，tcp/udp等。 Formats：负责媒体容器的处理，avi，mp4，ogg等。 Codecs：负责媒体的编解码，mp3，vorbis等。 Filters：负责媒体流的处理，converters，mixers，effects等。 Sinks：负责媒体流输出到指定设备或目的地，alsa，xvideo，tcp/udp等。 第三方插件 GStreamer组件 Element 所有可用组件的基础 一个Element实现一个功能 使用link point与外界交互（pad作为输入/输出端口） 一个Element可以有多个相同的pad 创建一个GstElement 借助工厂对象GstElementFactory，工厂对象根据name属性区分，首先找到要创建的element所属的工厂对象，在创建GstElement对象。 GstElementFatory *factory; factory = gst_element_factory_find(\"factory_name\")； GstElement *element; element = gst_element_factory_create(factory, \"element_name\"); 直接使用gst_element_factory_make(factory_name, element_name)1创建。 当不在使用GstElement时，需要使用gst_element_unref(GstElement *element)2来释放element对象占用的内存资源。gst_element_unref()会将元件的引用计数refcount减少1，refcount初始值为1，当refcount减少到0时元件被销毁。 gst_element_set_name(); //设置element对象的name gst_element_get_name(); //获取element对象的name 箱柜bin 容器：容纳其他元件对象，实际自身也是GstElement对象 同时管理多个Element：对bin的状态修改会同步到bin中所有的Element上，降低了应用的复杂度 顶层bin必须是一个pipeline 创建一个bin 借助工厂方法 GstElement *thread, *pipeline; // 创建线程对象，同时为其指定唯一的名称。 thread = gst_element_factory_make (\"thread\", NULL); // 根据给出的名称，创建一个特定的管道对象。 pipeline = gst_pipeline_new (\"pipeline_name\"); 直接使用gst_bin_new(\"bin_name\")创建 常用操作 使用gst_bin_add(GST_BIN(bin), element)将已存在的元件添加到bin中 使用gst_bin_get_by_name(\"GST_BIN(bin), \"element_name\")根据Element的name获取bin中的Element，由于bin可以嵌套bin，因此该函数会递归查找 使用gst_bin_remove (GST_BIN (bin), element)移除bin中的Element 元件的状态 GST_STATE_NULL：这是默认状态。在这种状态下没有分配资源，因此，转换到此状态将释放所有资源。当元件的引用计数达到0并被释放时，该元件必须处于此状态。 GST_STATE_READY：在就绪状态下，元件已分配了其所有全局资源，即可以保留在流中的资源。你可以考虑打开设备，分配缓冲区等。但是在这种状态下不会打开流，因此流位置自动为零。如果先前已打开流，则应在此状态下将其关闭，并应重置位置，属性等。 GST_STATE_PAUSED：在此状态下，元件已打开流，但未对其进行处理。此时元件可以修改流的位置，读取和处理数据，状态一旦更改为PLAYING，即可开始播放。总之，PAUSED与PLAYING相同，只是PAUSED没有运行时钟。 GST_STATE_PLAYING：在该PLAYING状态下，与该PAUSED状态下完全相同，只是时钟现在运行。 使用gst_element_set_state(element, GST_STATE_PLAYING)修改元件状态 衬垫Pad 衬垫是元件与外界的链接通道，它必须依附于某个元件，有src和sink两个端口 获取元件的衬垫pad：gst_element_get_pad(element, \"src\") gst_element_get_pad_list(element)获取元件所有的衬垫 gst_pad_get_parent(GstPad *)可以获得指定衬垫所属的元件 gst_pad_get_name(GstPad *); gst_pad_set_name(GstPad *); Pad link GstPad *srcpad, *sinkpad; srcpad = gst_element_get_pad(element1, \"src\"); sinkpad = gst_element_get_pad(element2, \"sink\"); //连接 gst_pad_link(srcpad, sinkpad); //断开 gst_pad_unlink(srcpad. sinkpad); Pad Capability 描述元件的功能 GstCaps *caps; caps = gst_pad_get_caps (pad); g_print (\"pad name is: %s\\n\", gst_pad_get_name (pad)); while (caps) { g_print (\" Capability name is %s, MIME type is %s\\n\", gst_caps_get_name (caps), gst_caps_get_mime (caps)); caps = caps->next; } Pad Capability for Filtering 通过gst_caps_new_simole()限制两个Element之间的数据流格式 static gboolean // link_elements_with_filter (GstElement *element1, GstElement *element2) { gboolean link_ok; GstCaps *caps; caps = gst_caps_new_simple (\"video/x-raw\", \"format\", G_TYPE_STRING, \"I420\", \"width\", G_TYPE_INT, 384, \"height\", G_TYPE_INT, 288, \"framerate\", GST_TYPE_FRACTION, 25, 1, NULL); link_ok = gst_element_link_filtered (element1, element2, caps); gst_caps_unref (caps); if (!link_ok) { g_warning (\"Failed to link element1 and element2!\"); } return link_ok; } Ghost Pad bin没有属于自己的src pad和sink pad，因此引入ghost pad，将其与第一个Element的sink pad和最后一个Element的src pad相连接，对bin的操作实际想让与对Element的pad操作 动态衬垫 Dynamic pads 创建元件时某些元件不一定会立即生成所有的pad oggdemux元件创建时只有一个sink pad，它会根据接收到的ogg流信息为ogg流动态创建src pad，并在接受完之后动态删除创建的src pad Bus Bus是gstreamer内部用于将消息从内部不同的streaming线程，传递到bus线程，再由bus所在线程将消息发送到应用程序。应用程序只需要向bus注册消息处理函数，即可接收到pipline中各element所发出的消息，使用bus后，应用程序就不用关心消息是从哪一个线程发出的，避免了处理多个线程同时发出消息的复杂性。 Gstreamer数据消息交互 2: "},"I2C/I2C通信协议.html":{"url":"I2C/I2C通信协议.html","title":"I2C Protocol","keywords":"","body":" Introduction I2C总线物理拓扑结构 主从设备 双向传输 I2C通信 数据有效性 起始条件S和停止条件P 数据传输格式 响应ACK 设备地址 I2C读写操作 linux/i2c.h 参考 I2C通信协议 Introduction I2C(Inter-integrated circuit)总线是由Philips公司开发的一种简单、双向二线制同步串行总线，目前被广泛应用在系统内多个IC间的通信。 I2C是一个能够支持多个设备的总线，包含一条双向串行数据线SDA，一条串行时钟线SCL。每个连接到总线的设备都有一个独立的地址，主机可以通过该地址来访问不同设备。主机通过SDA线发送设备地址（SLAVE_ADDRESS）查找从机，SLAVE_ADDRESS可以是7位或10位，紧跟着SLAVE_ADDRESS的一个数据位用来表示数据传输方向，即第8位或11位。为0时表示写数据，为1时表示读数据。 I2C总线物理拓扑结构 SCL(serial clock)：时钟线，传输CLK信号，只能由主设备产生，通信时通信双方工作在同一时钟下。 SDA(serial data)：数据线，I2C所有数据以字节为单位在SDA线上串行传输。 通过对SCL和SDA线高低电平时序进行通信。 主从设备 通信由主设备发起，由主设备主导，从设备只是按照I2C协议被动的接受主设备的通信，并及时响应，主从设备可以由通信双方决定，但通常在硬件设计时指定。 I2C通信可以一对一（一个主设备对1个从设备），也可以一对多（一个主设备对多个从设备）。 主设备负责调度总线，决定某一时刻和哪个从设备通信。同一时刻，I2C的总线上只能传输一对设备的通信信息，所以同一时刻只能有一个从设备和主设备通信（一对多通信时实际由于通信速度快用户并不会察觉到时延）。 双向传输 主设备通过一根SDA线既可以把数据发给从设备，也可以从SDA上读取数据，连接SDA线的引脚里面有两个引脚（发送引脚/接受引脚），使用开极(极电集开发出去作为输出)电路选择功能。 当某一个芯片不想影响SDA线时，那就不驱动这个三极管。 想输出高电平时（读）；都不驱动(高电平就由上拉电阻决定)。 想输出低电平（写），就驱动三极管。 I2C通信 数据有效性 SDA线上的数据必须在时钟的高电平周期保持稳定，数据线的高或低电平状态只有在 SCL线的时钟信号是低电平时才能改变。 换言之，SCL为高电平时表示有效数据，SDA为高电平表示“1”，低电平表示“0”；SCL为低电平时表示无效数据，此时SDA会进行电平切换，为下次数据表示做准备，即SCL在CLK上升沿锁存数据，接下来一个时钟周期要传输的数据必须在CLK上升沿到来前提前准备好。 起始条件S和停止条件P 起始条件S：当SCL高电平时，SDA由高电平向低电平转换。 停止条件P：当SCL高电平时，SDA由低电平向高电平转换。 起始和停止条件一般由主机产生。总线在起始条件后处于忙碌的状态，由本次数据传输的主从设备独占，在停止条件的某段时间后，主设备释放总线才再次处于空闲状态。 数据传输格式 传输的每个字节必须为8位，而总字节数不受限制。每个字节后必须跟一个ACK响应位。首先开始传输的是数据最高位，即MSB位。如果此时从机正忙于其他功能，如正在中断服务程序，则需要使SCL线保持低电平迫使主机进入等待状态，直到从机准备完成。 响应ACK 数据接收方收到传输的一个字节数据后，需要给出响应，此时处在第九个时钟，发送端释放SDA线控制权，将SDA电平拉高，由接收方控制。若希望继续，则给出“应答（ACK）”信号，即SDA为低电平；反之给出“非应答（NACK）”信号，即SDA为高电平。 设备地址 I2C总线上的每一个设备都对应一个唯一的地址，主从设备之间的数据传输是建立在地址的基础上，也就是说，主设备在传输有效数据之前 要先指定从设备的地址，地址指定的过程和上面数据传输的过程一样，只不过大多数从设备的地址是7位的，然后协议规定再给地址添加一个最低位用来表示接下来 数据传输的方向，0表示主设备向从设备写数据，1表示主设备向从设备读数据。 I2C读写操作 关于读数据 读数据时第一次通信写入寄存器内部单元地址，这时从设备将根据寄存器地址将数据取出放入从设备的I2C输出buffer中，第二次通信将读寄存器中的数据读出并返回给主设备。 读单个字节数据不需要等待应答，写入寄存器地址后需要再次开启一个新的I2C通信。 linux/i2c.h 参考 I2C协议（上）——基础介绍 I2C总线协议详解 [Linux]I2C设备读写及文件节点创建](https://www.cnblogs.com/all-for-fiona/p/3949654.html) "},"Linux_Driver_Model/Linux内核整体框架.html":{"url":"Linux_Driver_Model/Linux内核整体框架.html","title":"Linux 内核整体框架","keywords":"","body":" 整体框架 Process Scheduler Memory Manage Virtual File System NET Inter-Process Communication Linux内核目录含义 设备驱动模型 Bus Class Device Device Driver Device & Device Driver Linux内核整体框架 整体框架 Process Scheduler 进程调度，提供对CPU的访问控制，主要包括以下四个模块： Scheduling Poliicy：进程调度策略，决定能够拥有CPU资源的进程 Architecture-specific Schedulers：体系结构相关部分，用于对不同的CPU的控制，实际与CPU相连的部分 Architecture-independent Scheduler：体系结构无关部分，与Scheduling Policy共同决定要执行的进程，然后传给Architecture-specific Scheduler来resume制定进程 System Call Interface：系统调用接口，为用户空间的操作提供接口 Memory Manage 提供对内存资源的访问控制。Linux内核提供虚拟内存机制，以进程为单位，将进程使用的虚拟内存映射到实际的硬件物理内存上，以扩大进程能够调用的内存资源。 Architecture Specific Managers：体系结构相关部分。提供用于访问硬件Memory的虚拟接口。 Architecture Independent Manager：体系结构无关部分。提供所有的内存管理机制，包括：以进程为单位的memory mapping；虚拟内存的Swapping。 System Call Interface：系统调用接口。通过该接口，向用户空间程序应用程序提供内存的分配、释放，文件的map等功能。 Virtual File System VFS将不同功能的外部设备抽象成文件，通过统一的文件操作接口（Device Driver）来访问。 Device Drivers：设备驱动，用于控制所有的外部设备及控制器。 Device Independent Interface：该模块定义了描述硬件设备的统一方式（统一设备模型），所有的设备驱动都遵守这个定义，可以降低开发的难度。同时可以用一致的形式向上提供接口。 Logical Systems：每一种文件系统，都会对应一个Logical System（逻辑文件系统），它会实现具体的文件系统逻辑。 System Independent Interface：该模块负责以统一的接口（块设备和字符设备）表示硬件设备和逻辑文件系统，这样上层软件就不再关心具体的硬件形态了。 System Call Interface：系统调用接口，向用户空间提供访问文件系统和硬件设备的统一的接口。 NET 负责管理系统的网络设备，并实现多种多样的网络标准。网卡作为外部设备，按照Linux“一切皆文件”的设计思想，NET也应该设计成文件接口，事实上NET子系统的设计也与VFS类似，但是由于网络协议的设计和多样性，系统为了隐去设备的实现细节方便用户操作将其单独划分成一个部分（因此Linux也不完全是“文件”）。 Network Device Drivers：网络设备的驱动，和VFS子系统中的设备驱动是一样的。 Device Independent Interface：和VFS子系统中的是一样的。 Network Protocols：实现各种网络传输协议，例如IP, TCP, UDP等等。 Protocol Independent Interface：屏蔽不同的硬件设备和网络协议，以相同的格式提供接口（socket)。 System Call interface：系统调用接口，向用户空间提供访问网络设备的统一的接口。 Inter-Process Communication 进程间通信 Linux内核目录含义 include/ ---- 内核头文件，需要提供给外部模块（例如用户空间代码）使用。 kernel/ ---- Linux内核的核心代码，包含了3.2小节所描述的进程调度子系统，以及和进程调度相关的模块。 mm/ ---- 内存管理子系统（3.3小节）。 fs/ ---- VFS子系统（3.4小节）。 net/ ---- 不包括网络设备驱动的网络子系统（3.5小节）。 ipc/ ---- IPC（进程间通信）子系统。 arch/ ---- 体系结构相关的代码，例如arm, x86等等。 arch/mach ---- 具体的machine/board相关的代码。 arch/include/asm ---- 体系结构相关的头文件。 arch/boot/dts ---- 设备树（Device Tree）文件。 init/ ---- Linux系统启动初始化相关的代码。 block/ ---- 提供块设备的层次。 sound/ ---- 音频相关的驱动及子系统，可以看作“音频子系统”。 drivers/ ---- 设备驱动（在Linux kernel 3.10中，设备驱动占了49.4的代码量）。 lib/ ---- 实现需要在内核中使用的库函数，例如CRC、FIFO、list、MD5等。 crypto/ ----- 加密、解密相关的库函数。 security/ ---- 提供安全特性（SELinux）。 virt/ ---- 提供虚拟机技术（KVM等）的支持。 usr/ ---- 用于生成initramfs的代码。 firmware/ ---- 保存用于驱动第三方设备的固件。 samples/ ---- 一些示例代码。 tools/ ---- 一些常用工具，如性能剖析、自测试等。 Kconfig, Kbuild, Makefile, scripts/ ---- 用于内核编译的配置文件、脚本等。 COPYING ---- 版权声明。 MAINTAINERS ----维护者名单。 CREDITS ---- Linux主要的贡献者名单。 REPORTING-BUGS ---- Bug上报的指南。 Documentation, README ---- 帮助、说明文档。 设备驱动模型 Bus A bus is a channel between the processor and one or more devices. For the purposes of the device model, all devices are connected via a bus, even if it is an internal, virtual, \"platform\" bus. Buses can plug into each other. A USB controller is usually a PCI device, for example. The device model represents the actual connections between buses and the devices they control. A bus is represented by the bus_type structure. It contains the name, the default attributes, the bus' methods, PM operations, and the driver core's private data. 总线是CPU和一个或多个设备之间信息交互的通道 总线可以互相嵌套 Class A class is a higher-level view of a device that abstracts out low-level implementation details. Drivers may see a SCSI disk or an ATA disk, but, at the class level, they are all simply disks. Classes allow user space to work with devices based on what they do, rather than how thet are connected or how they work. class与面向对象程序设计中的class相似，集合具有相似功能或属性的设备，抽象出一套在多个设备之间共用的属性和接口函数，对用户空间隐去实现细节，减少重复劳动。 Device At the lowest level, every device in a Linux system is represented by an instance of struct device. The device structure contains the information that the device model core needs to model the system. Most subsystems, however, track additional information about the devices they host. As a result, it is rare for devices to be represented by bare device structures; instead, that structure, like kobject structures, is usually embedded within a higher-level representation of the device. 抽象设备的各种属性以便于计算机识别设备 Device Driver The device driver-model tracks all of the drivers known to the system. The main reason for this tracking is to enable the driver core to match up drivers with new devices. Once drivers are known objects within the system, however, a number of other things become possible. Device drivers can export information and configuration variables that are independent of any specific device. 抽象硬件设备的驱动程序为用户空间提供对设备的相关操作 Device & Device Driver Device描述设备“有什么用” Driver描述“怎么去用设备” 设备驱动模型一直遍历系统中所有的驱动，当没有Device注册时，对应的Device Driver不执行初始化操作，一旦有新的Device注册，那么就是根据名字进行match，如果名字相同就执行Device Driver中的初始化函数（probe），初始化设备使其为可用状态。 "},"Linux_Driver_Model/Kobject.html":{"url":"Linux_Driver_Model/Kobject.html","title":"KObject","keywords":"","body":" Foreword Kobject & Kset & Ktype Kobject Kset Ktype Kobject初始化 kmalloc分配 kobject_create(void)分配 Kset的初始化和注册 kset_init(struct kset *kset) kset_create_and_add() Kobject和Kset Kset和Kobject的关系 Kset和Kobject的层次结构 Kobject Foreword Linux设备模型的核心是使用Bus、Class、Device、Driver四个核心数据结构，将大量的、不同功能的硬件设备抽象并以树状结构进行管理。但是硬件设备繁多，每一个都描述成一个对应的结构体将产生大量的代码冗余，因此Linux参考面向对象程序设计思想，将设备模型数据结构中可能相同的部分单独抽象出来统一实现——Kobject。 Kobject不会单独出现，通常内嵌在大型数据结构中，为其提供一些底层的功能实现 驱动开发者通常很少使用Kobject以及它提供的接口，而是使用构建在Kobject上的设备模型接口 Kobject & Kset & Ktype Kobject /* state_initialized，指示该Kobject是否已经初始化，以在Kobject的Init，Put，Add等操作时进行异常校验。 state_in_sysfs，指示该Kobject是否已在sysfs中呈现，以便在自动注销时从sysfs中移除。 state_add_uevent_sent/state_remove_uevent_sent，记录是否已经向用户空间发送ADD uevent，如果有，且没有发送remove uevent，则在自动注销时，补发REMOVE uevent，以便让用户空间正确处理。 uevent_suppress，如果该字段为1，则表示忽略所有上报的uevent事件。 Uevent提供了“用户空间通知”的功能实现，通过该功能，当内核中有Kobject的增加、删除、修改等动作时，会通知用户空间。 */ struct kobject { const char *name; // struct list_head entry; struct kobject *parent; struct kset *kset; struct kobj_type *ktype; struct kernfs_node *sd; /* sysfs directory entry */ struct kref kref; //reference count #ifdef CONFIG_DEBUG_KOBJECT_RELEASE struct delayed_work release; #endif unsigned int state_initialized:1; unsigned int state_in_sysfs:1; unsigned int state_add_uevent_sent:1; unsigned int state_remove_uevent_sent:1; unsigned int uevent_suppress:1; }; entry：用于将Kobject加入Kset中的list_head parent：指向父节点，以此形成层次结构。如果当前kobject没有指定parent，但是又有kset，那么parent将会指向kset，如果两者都没有，那么kobject将作为根节点 kset：kobject所属的kset，可以为NULL。 ktype：kobject的ktype，没有会报错 sd：该kobject在sysfs中的目录入口 kref：kobject的引用计数器 Kset struct kset { struct list_head list; spinlock_t list_lock; struct kobject kobj; const struct kset_uevent_ops *uevent_ops; }; list/list_lock：用于保存该kset下所有的kobject的链表。 kobj：该kset自己的kobject（kset是一个特殊的kobject，也会在sysfs中以目录的形式体现）。 uevent_ops：该kset的uevent操作函数集。当任何kobject需要上报uevent时，都要调用它所从属的kset uevent_ops，添加环境变量，或者过滤event（kset可以决定哪些event可以上报）。因此，如果一个kobject不属于任何kset时，是不允许发送uevent的。 Ktype struct kobj_type { void (*release)(struct kobject *kobj); const struct sysfs_ops *sysfs_ops; struct attribute **default_attrs; const struct kobj_ns_type_operations *(*child_ns_type)(struct kobject *kobj); const void *(*namespace)(struct kobject *kobj); }; release：通过该回调函数，可以将包含该种类型kobject的数据结构的内存空间释放掉。 sysfs_ops：该种类型的Kobject的sysfs文件系统接口。 default_attrs：该种类型的Kobject的atrribute列表（所谓attribute，就是sysfs文件系统中的文件）。将会在Kobject添加到内核时，一并注册到sysfs中。 child_ns_type/namespace：和文件系统（sysfs）的命名空间有关，这里不再详细说明。 Kobject初始化 kmalloc分配 通常随上层数据结构一同分配并在初始化后添加到kernel 这种方式分配的kobject，会在引用计数变为0时，由kobject_put调用其ktype的release接口，释放内存空间 kobject_create(void)分配 kobject_create内置了一个的默认的ktype（dynamic_kobj_ktype）用于在refcount = 0时释放空间 Kset的初始化和注册 kset_init(struct kset *kset) 用于初始化已分配的kset（通常使用kmalloc随上层数据结构一同分配），kset->kobject->ktype必须有上层数据结构提供 kset是一个特殊的kobject，因此kset的初始化会调用kobject的初始化接口 kset_create_and_add() 调用kset_create()动态申请一个kset并register Kobject和Kset Kset和Kobject的关系 Kset和Kobject的层次结构 Kset和Kobject通过list_head这个链表链接在一起，list_head是一个双向链表，同一kset下的kobject被组织成一个双向循环链表，其中kset的struct list_head list是链表的表头，kset下的kobject中的struct list_head entry是list中的一个节点，kset和kobject之间的包含关系实际上是一层层的循环链表的交织，对应/sys/目录下的一层层目录或文件12。 kset(/sys/bus) +--------+ | kobj | | | +--------+ | list | +------------+--------+ | | | /sys/bus/pci v +--------+ /sys/bus/term1 /sys/bus/term2| | +--------+ +--------+ | kobj | | | | +--->+ | | kobj +---->+ kobj | +--------+ | | | | | list | +--------+ +--------+ +---+----+ | v /sys/bus/pci/term3 +--------+ | kobj | +--------+ 1. kobject可以通过parent指针（或kset指针）直接找到上层节点（或kset），类比cd指令可以要返回上层目录只需要cd .. ↩ 2. 而要从上层访问指定的kobject，必须要有完整的节点地址，类比cd指令要进入制定目录需要使用完整的路径（相对路径需要准确的目录名） ↩ "},"Linux_Driver_Model/Uevent.html":{"url":"Linux_Driver_Model/Uevent.html","title":"Uevent","keywords":"","body":" Uevent事件 kobj_uevent_env kset_uevent_ops kobject_uevent_env() Uevent Uevent是Kobject的一部分，负责通知用户空间Kobject的状态变化，用户控件根据变化做出相应的处理。 Uevent事件 /* * The actions here must match the index to the string array * in lib/kobject_uevent.c * * Do not add new actions here without checking with the driver-core * maintainers. Action strings are not meant to express subsystem * or device specific properties. In most cases you want to send a * kobject_uevent_env(kobj, KOBJ_CHANGE, env) with additional event * specific variables added to the event environment. */ enum kobject_action { KOBJ_ADD, KOBJ_REMOVE, KOBJ_CHANGE, KOBJ_MOVE, KOBJ_ONLINE, KOBJ_OFFLINE, KOBJ_MAX }; kobj_uevent_env 用于此次时间上报的环境变量 #define UEVENT_HELPER_PATH_LEN 256 #define UEVENT_NUM_ENVP 32 /* number of env pointers */ #define UEVENT_BUFFER_SIZE 2048 /* buffer for the variables */ struct kobj_uevent_env { char *argv[3]; char *envp[UEVENT_NUM_ENVP]; int envp_idx; char buf[UEVENT_BUFFER_SIZE]; int buflen; }; envp：用于保存环境变量的地址 envp_idx：用于访问envp的index buf：保存环境变量的buffer buflen：访问buf的变量 kset_uevent_ops struct kset_uevent_ops { int (* const filter)(struct kset *kset, struct kobject *kobj); const char *(* const name)(struct kset *kset, struct kobject *kobj); int (* const uevent)(struct kset *kset, struct kobject *kobj, struct kobj_uevent_env *env); }; filter：kset通过filter过滤掉不希望kobject上报的event name：返回kset的name，如果kset没有合法的name，那么这个kset下的所有kobject将不允许上报uevent uevent：kset为kobject同意添加环境变量 kobject_uevent_env() 默认使用Kmod上传用户事件，如果定义了CONFIG_NET关键字，则使用Netlink上报事件。 /** * kobject_uevent_env - send an uevent with environmental data * * @action: action that is happening * @kobj: struct kobject that the action is happening to * @envp_ext: pointer to environmental data * * Returns 0 if kobject_uevent_env() is completed with success or the * corresponding error when it fails. */ int kobject_uevent_env(struct kobject *kobj, enum kobject_action action, char *envp_ext[]) { struct kobj_uevent_env *env; const char *action_string = kobject_actions[action]; const char *devpath = NULL; const char *subsystem; struct kobject *top_kobj; struct kset *kset; const struct kset_uevent_ops *uevent_ops; int i = 0; int retval = 0; #ifdef CONFIG_NET struct uevent_sock *ue_sk; #endif pr_debug(\"kobject: '%s' (%p): %s\\n\", kobject_name(kobj), kobj, __func__); /* search the kset we belong to 知道到该kobj从属的kset*/ top_kobj = kobj; while (!top_kobj->kset && top_kobj->parent) top_kobj = top_kobj->parent; /* 找的方法很简单,若它的kset不存在,则查找其父节点的kset是否存在,不存在则继续查找父父节点.... */ if (!top_kobj->kset) { pr_debug(\"kobject: '%s' (%p): %s: attempted to send uevent \" \"without kset!\\n\", kobject_name(kobj), kobj, __func__); return -EINVAL; /* 最终还没找到就报错 */ } kset = top_kobj->kset; /* 找到与之相关的kset */ uevent_ops = kset->uevent_ops; /* skip the event, if uevent_suppress is set*/ if (kobj->uevent_suppress) { /* uevent_suppress被置位,则忽略上报uevent */ pr_debug(\"kobject: '%s' (%p): %s: uevent_suppress \" \"caused the event to drop!\\n\", kobject_name(kobj), kobj, __func__); return 0; } /* skip the event, if the filter returns zero. */ if (uevent_ops && uevent_ops->filter) /* 所属的筛选函数存在则筛选,返回0表示被筛掉了,不再上报 */ if (!uevent_ops->filter(kset, kobj)) { pr_debug(\"kobject: '%s' (%p): %s: filter function \" \"caused the event to drop!\\n\", kobject_name(kobj), kobj, __func__); return 0; } /* originating subsystem */ if (uevent_ops && uevent_ops->name) subsystem = uevent_ops->name(kset, kobj); /* name函数存在,则使用kset返回的kset的name */ else subsystem = kobject_name(&kset->kobj); /* 否则用kset里kobj的name做kset的name */ if (!subsystem) { /* kset的name不存在,也不允许上报 */ pr_debug(\"kobject: '%s' (%p): %s: unset subsystem caused the \" \"event to drop!\\n\", kobject_name(kobj), kobj, __func__); return 0; } /* environment buffer */ env = kzalloc(sizeof(struct kobj_uevent_env), GFP_KERNEL); /* 分配一个用于此次环境变量的buffer */ if (!env) return -ENOMEM; /* complete object path */ devpath = kobject_get_path(kobj, GFP_KERNEL); /* 根据kobj得到它在sysfs中的路径 */ if (!devpath) { retval = -ENOENT; goto exit; } /* default keys 添加当前要上报的行为,path,name到env的buffer中 */ retval = add_uevent_var(env, \"ACTION=%s\", action_string); if (retval) goto exit; retval = add_uevent_var(env, \"DEVPATH=%s\", devpath); if (retval) goto exit; retval = add_uevent_var(env, \"SUBSYSTEM=%s\", subsystem); if (retval) goto exit; /* keys passed in from the caller */ if (envp_ext) { /* 我们自己传的外部环境变量要不为空,则解析并添加到env的buffer中 */ for (i = 0; envp_ext[i]; i++) { retval = add_uevent_var(env, \"%s\", envp_ext[i]); if (retval) goto exit; } } /* let the kset specific function add its stuff */ if (uevent_ops && uevent_ops->uevent) { /* 如果uevent_ops中的uevent存在,则调用该接口发送该kobj的env */ retval = uevent_ops->uevent(kset, kobj, env); if (retval) { pr_debug(\"kobject: '%s' (%p): %s: uevent() returned \" \"%d\\n\", kobject_name(kobj), kobj, __func__, retval); goto exit; } } /* * Mark \"add\" and \"remove\" events in the object to ensure proper * events to userspace during automatic cleanup. If the object did * send an \"add\" event, \"remove\" will automatically generated by * the core, if not already done by the caller. */ if (action == KOBJ_ADD) /* 如果action是add或remove的话要更新kobj中的state */ kobj->state_add_uevent_sent = 1; else if (action == KOBJ_REMOVE) kobj->state_remove_uevent_sent = 1; mutex_lock(&uevent_sock_mutex); /* we will send an event, so request a new sequence number */ /* 每次发送一个事件,都要有它的事件号,该事件号不能重复,u64 uevent_seqnum,把它也作为环境变量添加到buffer最后面 */ retval = add_uevent_var(env, \"SEQNUM=%llu\", (unsigned long long)++uevent_seqnum); if (retval) { mutex_unlock(&uevent_sock_mutex); goto exit; } #if defined(CONFIG_NET) /* send netlink message 如果定义了\"CONFIG_NET”，则使用netlink发送该uevent */ list_for_each_entry(ue_sk, &uevent_sock_list, list) { struct sock *uevent_sock = ue_sk->sk; struct sk_buff *skb; size_t len; if (!netlink_has_listeners(uevent_sock, 1)) continue; /* allocate message with the maximum possible size */ len = strlen(action_string) + strlen(devpath) + 2; skb = alloc_skb(len + env->buflen, GFP_KERNEL); if (skb) { char *scratch; /* add header */ scratch = skb_put(skb, len); sprintf(scratch, \"%s@%s\", action_string, devpath); /* copy keys to our continuous event payload buffer */ for (i = 0; i envp_idx; i++) { len = strlen(env->envp[i]) + 1; scratch = skb_put(skb, len); strcpy(scratch, env->envp[i]); } NETLINK_CB(skb).dst_group = 1; retval = netlink_broadcast_filtered(uevent_sock, skb, 0, 1, GFP_KERNEL, kobj_bcast_filter, kobj); /* ENOBUFS should be handled in userspace */ if (retval == -ENOBUFS || retval == -ESRCH) retval = 0; } else retval = -ENOMEM; } #endif mutex_unlock(&uevent_sock_mutex); /* call uevent_helper, usually only enabled during early boot */ if (uevent_helper[0] && !kobj_usermode_filter(kobj)) { char *argv [3]; /* 添加helper和 kset的name */ argv [0] = uevent_helper; argv [1] = (char *)subsystem; argv [2] = NULL; /* 添加了标准环境变量 （HOME=/，PATH=/sbin:/bin:/usr/sbin:/usr/bin）*/ retval = add_uevent_var(env, \"HOME=/\"); if (retval) goto exit; retval = add_uevent_var(env, \"PATH=/sbin:/bin:/usr/sbin:/usr/bin\"); if (retval) goto exit; /* 调用kmod模块提供的call_usermodehelper函数，上报uevent。call_usermodehelper的作用，就是fork一个进程，以uevent为参数，执行uevent_helper */ retval = call_usermodehelper(argv[0], argv, env->envp, UMH_WAIT_EXEC); } exit: kfree(devpath); kfree(env); return retval; } env：环境变量 const char *action_string = kobject_actions[action];：将enum kobject_action枚举类型转化成字符串 subsystem：kset的name，如果存在uevent_ops->name则用其返回值，否则用kset的name（kobject_name(&kset->kobj)） devpath：根据kobj获取它在sysfs下的地址 top_kobj：找到kobj的从属kset，一个kobj必须从属于一个kset才能上报uevent kobj->uevent_suppress：kobj的uevent忽略置位 uevent_ops->filter：kset存在filter，如果filter返回0，表示该uevent被筛除，不需要上报 add_uevent_var：以格式化字符的形式将action、路径信息、subsystem等信息传给env中 将传入的envp解析并添加到env中 将env传给uevnet_ops->uevent KOBJ_ADD和KOBJ_REMOVE需要修改kobj的对应uevent置位 每个事件必须有不重复的事件号 "},"Linux_Driver_Model/Review_of_the_Training.html":{"url":"Linux_Driver_Model/Review_of_the_Training.html","title":"A simple sample","keywords":"","body":" 前言 Chapter I：Requirements Chapter II：Introduction 2.1驱动编译 2.2模块化机制 Chapter II：Introduction 2.1驱动编译 2.2模块化机制 2.3字符设备注册 2.3.1 static struct char_device_struct 2.3.2字符设备注册函数 2.4.应用层调用驱动 Chapter III：A Simple Demo Chapter IV：Development 4.1 probe() 4.2 ioctl() 4.2.1 unlocked_ioctl() 4.2.2 timer 4.2.3 workqueue 4.3 sysfs 4.3.1 sysfs的创建 4.3.2 sysfs.read/sysfs.write Review of the Training 前言 入职培训项目，Android和Linux驱动开发相关，可惜我十分抗拒学习Java相关技术，所以没法完整的主导项目的实现，最终结果不尽人意，以下只对BSP部分进行记录。在培训结束的时候指导教师说抛出一个问题，你不能因为不符合你的技术栈你就不去做，因此考虑趁着还有双休，考虑完成前端的部分。 Chapter I：Requirements 分配一段内存，模拟成一个字符设备，写出其驱动程序。 驱动中应该实现probe, store, show, open, read, write, ioctrl等函数。 ioctrl 可以接收特定的命令实现对应的操作。 a) 当输入 A 时 A 线程启动，且定时打印该段内存的信息（使用 timer 实现）； b) 当输入 B 时 B 线程启动，且定时打印该段内存的信息（使用 workqueue 实现）； 能够使用sysfs api创建文件节点（节点位置 /sys/test/meminfo） meminfo显示内存信息，内容由学员发挥。 驱动允许上层APP进行加载和卸载，APP可以对设备节点进行访问。 生成 /dev/write /dev/read /dev/InOut 三个设备节点,并可以供上层进行数据交换 Chapter II：Introduction 2.1驱动编译 #dir of linux kernel KERN_PATH:=/lib/modules/$(shell uname -r )/build all: make -C $(KERN_PATH) M=$(shell pwd) modules clean: make -C $(KERN_PATH) M=$(shell pwd) clean #dynamic load module obj-m:=probe.o read.o write.o 2.2模块化机制 模块代码有两种运行方式，一是静态编译连接进内核，在系统启动过程中进行初始化；一是编译成可动态加载的module，通过insmod动态加载重定位到内核。这两种方式可以在Makefile中通过obj-y或obj-m选项进行选择。 而一旦可动态加载的模块目标代码（.ko）被加载重定位到内核，其作用域和静态链接的代码是完全等价的。所以这种运行方式的优点显而易见： 可根据系统需要动态加载模块，以扩充内核功能，不需要时将其卸载，以释放内存空间； 当需要修改内核功能时，只需编译相应模块，而不必重新编译整个内核。 缺点在于本机一旦关机，动态加载的module也将被卸载，因此某些内核必须的模块如vfs、platform_bus等都采用静态编译。 Chapter II：Introduction 2.1驱动编译 #dir of linux kernel KERN_PATH:=/lib/modules/$(shell uname -r )/build all: make -C $(KERN_PATH) M=$(shell pwd) modules clean: make -C $(KERN_PATH) M=$(shell pwd) clean #dynamic load module obj-m:=probe.o read.o write.o 2.2模块化机制 模块代码有两种运行方式，一是静态编译连接进内核，在系统启动过程中进行初始化；一是编译成可动态加载的module，通过insmod动态加载重定位到内核。这两种方式可以在Makefile中通过obj-y或obj-m选项进行选择。 而一旦可动态加载的模块目标代码（.ko）被加载重定位到内核，其作用域和静态链接的代码是完全等价的。所以这种运行方式的优点显而易见： 可根据系统需要动态加载模块，以扩充内核功能，不需要时将其卸载，以释放内存空间； 当需要修改内核功能时，只需编译相应模块，而不必重新编译整个内核。 缺点在于本机一旦关机，动态加载的module也将被卸载，因此某些内核必须的模块如vfs、platform_bus等都采用静态编译。 #include // module_init module_exit #include // __init __exit // install module static int __init demo_init(void) { printk(KERN_INFO \"helloworld~\\n\"); return 0; } // uninstall module static void __exit demo_exit(void) { printk(KERN_INFO \"goodbye world~\\n\"); } module_init(demo_init); module_exit(demo_exit); //use MODULE_xxx to decribe mudole info MODULE_LICENSE(\"GPL\"); // license MODULE_AUTHOR(\"aston\"); //author insmod *.ko：安装驱动，使用module_init定义一个变量名init_module，其指针指向的地址与初始化函数相同 2.3字符设备注册 2.3.1 static struct char_device_struct 所有字符型设备都由一个一个char_device_struct结构体描述： static struct char_device_struct { struct char_device_struct *next; //list struct unsigned int major; //major num unsigned int baseminor; //minor num int minorct; //minor num range char name[64]; //device name struct cdev *cdev; } *chrdevs[CHRDEV_MAJOR_HASH_SIZE]; //array range 0~255 2.3.2字符设备注册函数 static inline int register_chrdev(unsigned int major, const char *name, const struct file_operations *fops) { return __register_chrdev(major, 0, 256, name, fops); } int __register_chrdev(unsigned int major, unsigned int baseminor, unsigned int count, const char *name, const struct file_operations *fops) { struct char_device_struct *cd; struct cdev *cdev; cd = __register_chrdev_region(major, baseminor, count, name); cdev = cdev_alloc(); cdev->owner = fops->owner; cdev->ops = fops; kobject_set_name(&cdev->kobj, \"%s\", name); err = cdev_add(cdev, MKDEV(cd->major, baseminor), count); cd->cdev = cdev; return major ? 0 : cd->major; } register_chrdev调用了__register_chrdev_region，强制设定次设备号范围为0~255，并且封装了cdev_init和cdev_add。当在用户空间打开设备文件时内核可以根据设备号快速定位此设备文件的cdev->file_operations结构体,从而调用驱动底层的open,close,read,write,ioctl等函数。 int register_chrdev_region(dev_t from, unsigned count, const char *name) { struct char_device_struct *cd; dev_t to = from + count; dev_t n, next; for (n = from; n to) next = to; cd = __register_chrdev_region(MAJOR(n), MINOR(n), next - n, name); } return 0; } register_chrdev_region根据要求的范围申请连续设备编号，同时需要手动cdev_init和cdev_add static struct char_device_struct * __register_chrdev_region(unsigned int major, unsigned int baseminor, int minorct, const char *name) { struct char_device_struct *cd, **cp; int ret = 0; int i; cd = kzalloc(sizeof(struct char_device_struct), GFP_KERNEL); mutex_lock(&chrdevs_lock); /* * 如果major为0则分配一个没有使用的主设备号 * 注意，从chrdevs[255]开始向下查找 */ if (major == 0) { for (i = ARRAY_SIZE(chrdevs)-1; i > 0; i--) { if (chrdevs[i] == NULL) break; } if (i == 0) { ret = -EBUSY; goto out; } major = i; ret = major; } cd->major = major; cd->baseminor = baseminor; cd->minorct = minorct; strlcpy(cd->name, name, sizeof(cd->name)); // return major % CHRDEV_MAJOR_HASH_SIZE; // 根据major获得哈希chrdevs数组索引 i = major_to_index(major); // 寻找新设备插入的位置 // *cp表示当前元素存在，使用拉链法解决散列冲突 for (cp = &chrdevs[i]; *cp; cp = &(*cp)->next) if ((*cp)->major > major || //当前当前设备的主设备号大于要添加的设备的主设备号 ((*cp)->major == major && //如果主设备号相同，则根据次设备号找插入的位置 (((*cp)->baseminor >= baseminor) || ((*cp)->baseminor + (*cp)->minorct > baseminor))) ) break; // 防止重叠：新申请的连续次设备号不能和已申请的设备号重叠 if (*cp && (*cp)->major == major) { int old_min = (*cp)->baseminor; int old_max = (*cp)->baseminor + (*cp)->minorct - 1; int new_min = baseminor; int new_max = baseminor + minorct - 1; /* New driver overlaps from the left. */ if (new_max >= old_min && new_max = old_min) { ret = -EBUSY; goto out; } } // 将新申请的设备插入散列表 cd->next = *cp; *cp = cd; mutex_unlock(&chrdevs_lock); return cd; out: mutex_unlock(&chrdevs_lock); kfree(cd); return ERR_PTR(ret); } 2.6之前版本的内核使用register_chrdev来进行字符型设备的分配，每一个主设备号只能存放一种设备，它们使用相同的 file_operation 结构体，也就是说内核最多支持 256 个字符设备驱动程序。 从2.6版本开始新增了一个 register_chrdev_region 函数，它支持将同一个主设备号下的次设备号进行分段，每一段供给一个字符设备驱动程序使用，拓展了支持的设备数量。 内核使用一个chrdevs散列表来管理所有的字符设备驱动程序，数组范围[0~255]，索引方法为major%255，并使用拉链法解决寻址冲突。char_device_struct中的next指针可以指向主设备号相同的其他字符设备驱动程序，它们主设备号相同，各自次设备号相互之间不重叠，但共享同一个file_operation。 chrdevs数组的结构图 使用register_chrdev的话，不能指定此设备号，那么就会默认baseminor=0，count=256,造成了浪费。因为一个主设备号下的所有此设备号都只能对应同一个字符设备。使用__register_chrdev_region的话，则可以指定baseminor和count，就可以让一个主设备号下每一个次设备号都对应分配的字符设备。 if (major) { devid = MKDEV(major, 0); /* (major,0~1)对应fops, (major, 2~255)都不对应fops */ register_chrdev_region(devid, 2, \"demo\"); } else { /* (major,0~1)对应 fops, (major, 2~255)都不对应fops */ alloc_chrdev_region(&devid, 0, 2, \"demo\"); major = MAJOR(devid); } cdev_init(&cdev, &fops); cdev_add(&cdev, devid, 2); 2.4.应用层调用驱动 在字符设备注册阶段，register_chrdev将指向对应file_operation结构体的指针放入chrdevs数组major对应的位置中，file_operation包含了对硬件的所有操作，应用层通过调用file_operation的属性来对硬件进行相关操作。 struct file_operations { struct module *owner; loff_t (*llseek) (struct file *, loff_t, int); ssize_t (*read) (struct file *, char __user *, size_t, loff_t *); ssize_t (*write) (struct file *, const char __user *, size_t, loff_t *); ssize_t (*aio_read) (struct kiocb *, const struct iovec *, unsigned long, loff_t); ssize_t (*aio_write) (struct kiocb *, const struct iovec *, unsigned long, loff_t); int (*readdir) (struct file *, void *, filldir_t); unsigned int (*poll) (struct file *, struct poll_table_struct *); long (*unlocked_ioctl) (struct file *, unsigned int, unsigned long); long (*compat_ioctl) (struct file *, unsigned int, unsigned long); int (*mmap) (struct file *, struct vm_area_struct *); int (*open) (struct inode *, struct file *); int (*flush) (struct file *, fl_owner_t id); int (*release) (struct inode *, struct file *); int (*fsync) (struct file *, int datasync); int (*aio_fsync) (struct kiocb *, int datasync); int (*fasync) (int, struct file *, int); int (*lock) (struct file *, int, struct file_lock *); ssize_t (*sendpage) (struct file *, struct page *, int, size_t, loff_t *, int); unsigned long (*get_unmapped_area)(struct file *, unsigned long, unsigned long, unsigned long, unsigned long); int (*check_flags)(int); int (*flock) (struct file *, int, struct file_lock *); ssize_t (*splice_write)(struct pipe_inode_info *, struct file *, loff_t *, size_t, unsigned int); ssize_t (*splice_read)(struct file *, loff_t *, struct pipe_inode_info *, size_t, unsigned int); int (*setlease)(struct file *, long, struct file_lock **); }; 在用户空间open字符设备文件时，首先调用def_chr_fops->chrdev_open()函数(所有字符设备都调用此函数)，chrdev_open会调用kobj_lookup函数找到设备的cdev->kobject，从而得到设备的cdev,进而获得file_operations。 Chapter III：A Simple Demo Chapter IV：Development 需求中的前两点已经在Chapter III中实现，不再过多赘述，以下只针对需求中的难点以及我开发过程中遇到的问题和解决方法做一个review。 4.1 probe() bus是物理总线的抽象。 device是设备抽象，存在于bus之上。 driver是驱动抽象，注册到bus上，用于驱动bus上的特定device。 device和driver通过bus提供的match方法来匹配（通常是使用设备ID进行匹配）。 driver匹配到device后，调用driver的probe接口驱动device。 一个driver可以驱动多个相同的设备或者不同的设备。 probe函数其实就是接着init函数的工作完成设备的注册。 在理解了以上概念的基础上，应该对probe函数有了一个初步的了解，需求中的probe函数只是在bus上driver_mattch_device匹配成功后的与init相似的设备初始化函数，我们只需要简单了解probe函数的调用过程。 4.2 ioctl() Tips:ioctl()在2.6.35之后被unlocked_ioctl()所替代，区别在于ioctl由大内核锁保护，而unlocked_ioctl()需要自行实现锁机制。 4.2.1 unlocked_ioctl() /* 函数说明：应用程序向设备发送特定指令 Parameters： file - 打开的文件指针 cmd - 发送的命令 arg - Returns： long int */ #include long demo_ioctl(struct file *file, unsigned int cmd, unsigned long arg) { switch(cmd){ case A: timer_thread_run(); break; case B: wq = alloc_workqueue(\"wq\",0,0); INIT_WORK(&task, print_workqueue); queue_work(wq, &task); break; default: break; } printk(\"%s,%d\\n\",__func__,__LINE__); return 0; } unlocked_ioctl()实际根据应用程序发送来的指令执行特定的功能，实际是一个switch-case语句，其中第二个参数cmd是选择的参数。 cmd是一个32位无符号整数，被分为四个部分： type:魔数，占8位（_IOC_TYPEBITS），用于区分不同的驱动 number:序号，占8位（_IOC_NRBITS），用于给命令编号 direction：方向（读写），占2位（_IOC_DIRBITS） size:数据大小，占14位（_IOC_SIZEBITS） 内核要求cmd需要以这样的形式组织，并在中给出了_IO(type, number)宏定义用于将十进制数转化为符合格式的cmd指令。 /* 说明：ioctl api Parameters： fd - 文件 cmd - 经_IO重定义后的用户指令 TYPE - 用户指定的魔数 */ #include #define TYPE 'A' #define A _IO(TYPE, 1) #define B _IO(TYPE, 2) ioctl(fd, A); ioctl(fd, B); 4.2.2 timer 内核定时器：基于时钟滴答jiffies计数器，在不阻塞当前进程的情况下于未来某个特定时间点调度执行某个动作 struct timer_list { /* * All fields that change during normal runtime grouped to the * same cacheline */ struct hlist_node entry; unsigned long expires; void (*function)(struct timer_list *); u32 flags; #ifdef CONFIG_LOCKDEP struct lockdep_map lockdep_map; #endif }; expires：期望timer执行的jiffies值，到达jiffies值 时，将执行function绑定的函数 在==内核2.8==之前timer_list结构体比现在多一个data成员，作为传递给function的参数，本次开发使用的内核版本为==4.15== timer_list结构体使用前必须初始化，旧版本使用init_timer或是TIMER_INITIALIZER完成初始化，新版采用timer_setup(timer, callback, flags)完成初始化 struct timer_list timer; timer.expires = jiffies + 3 * HZ; timer_setup(&timer, print_process, 0); add_timer(&timer); // linux-2.8 // init_timer(&timer); // timer.function = print_process; // timer.data = 0; // add_timer(&timer); 4.2.3 workqueue workqueue:允许内核代码请求某个函数在将来的时间被调用 create_workqueue(const char *name)每个工作队列在创建时内核会在系统中的每个处理器上为该工作队列创建内核线程 向工作队列提交任务时需要填充一个work_struct结构 struct work_struct { atomic_long_t data; struct list_head entry; work_func_t func; #ifdef CONFIG_LOCKDEP struct lockdep_map lockdep_map; #endif }; INIT_WORKj将完成work_struct结构的初始化工作 queue_work和queue_delay_work将work添加到指定的workqueue中 static struct workqueue_struct *wq; static struct work_struct task; wq = alloc_workqueue(\"wq\",0,0); INIT_WORK(&task, print_workqueue); queue_delay_work(wq, &task, jiffies + 3 * HZ); 4.3 sysfs 4.3.1 sysfs的创建 kobject是隐藏在sysfs虚拟文件系统后的机制，对于sysfs中的每个目录，内核中都会存在一个对应的kobject。每个kobject输出一个或多个属性，在sysfs目录下表现为文件，因此要在sysfs目录下创建文件节点实际需要创建一个kobject。 struct kobject *my_kobj = NULL; my_kobj = kobject_create_and_add(\"test\", NULL); test通过kobject_set_name设置为唯一的kobject名，即sysfs中的目录名，kobject的kset和parent均为NULL的情况下，会在sysfs目录最高层创建文件。 4.3.2 sysfs.read/sysfs.write 创建kobject的时候会将一系列属性保存在kobj_type结构中 struct kobj_type { void (*release) (struct kobject *); struct sysfs_ops *sysfs_ops; struct attribute **default_attrs; } default_attrs成员保存了属性列表用于创建该类型的每一个kobject，sysfs_fs提供实现这些属性的方法 struct attribute { const char *name; umode_t mode; #ifdef CONFIG_DEBUG_LOCK_ALLOC bool ignore_lockdep:1; struct lock_class_key *key; struct lock_class_key skey; #endif }; struct sysfs_ops { ssize_t (*show)(struct kobject *, struct attribute *, char *); ssize_t (*store)(struct kobject *, struct attribute *, const char *, size_t); }; 由于需求要求创建sysfs/test/meminfo层次目录，而通过kobject和kset构建sysfs目录下的层次结构需要对两种结构间关系有深入了解，但这两种结构实在过于复杂，因此在查看源码后发现通过attribute_group可以创建子目录。 struct attribute_group { const char *name; umode_t (*is_visible)(struct kobject *, struct attribute *, int); umode_t (*is_bin_visible)(struct kobject *, struct bin_attribute *, int); struct attribute **attrs; struct bin_attribute **bin_attrs; }; name：If specified, the attribute group will be created in a new subdirectory with this name. static struct kobj_attribute my_sysfs_read =__ATTR(sysshow, S_IRUSR, demo_show, NULL); static struct kobj_attribute my_sysfs_write =__ATTR(syswrite, S_IWUSR, NULL,demo_store); static struct attribute *my_sysfs_attr[] = { &my_sysfs_read.attr, &my_sysfs_write.attr, NULL, }; static struct attribute_group my_sysfs_attr_group = { .name = \"meminfo\", //make sub_dir .attrs = my_sysfs_attr, }; #define __ATTR(_name, _mode, _show, _store) { \\ .attr = {.name = __stringify(_name), \\ .mode = VERIFY_OCTAL_PERMISSIONS(_mode) }, \\ .show = _show, \\ .store = _store, \\ } struct kobj_attribute { struct attribute attr; ssize_t (*show)(struct kobject *kobj, struct kobj_attribute *attr, char *buf); ssize_t (*store)(struct kobject *kobj, struct kobj_attribute *attr, const char *buf, size_t count); }; "},"OpenMax/OpenMAX概述.html":{"url":"OpenMax/OpenMAX概述.html","title":"OpenMAX概述","keywords":"","body":" 作用 框架 AL IL DL 组件 组成 IL Client Tunneled OpenMAX概述 OpenMax(Open Media Acceleration)开放多媒体加速器，也被称为OMX，是无授权费的、C语言编写的多媒体API标准，API提供了音频、视频、静态图片的一些常用处理操作的接口。目标是降低将多媒体软件移植到新的处理器和体系结构的成本和复杂性。 作用 加速跨OS和silicon平台的多媒体组件的开发、整合和编程，提高APP和多媒体接口跨平台可移植性1。 使library和codec实现者能够快速有效的利用新silicon的潜在的加速功能2，而不关心下层的硬件结构。 框架 根据官方文档OpenMAX主要分为AL、IL、DL三个层级 AL 多媒体应用（Media Player Application）和多媒体框架（Platform Media Framework，例如Android上的StageFright或MediaCodec API、Windows上的DirectShow、FFmpeg或Libav、GStreamer）的标准接口，使得应用在多媒体接口上具有了可移植性。 IL 提供多媒体框架和多媒体组件(如硬件或软件的音/视频编解码器)之间的标准化接口。 IL层使得应用程序与多媒体框架可以以一种统一的方式与多媒体编解码器对接，而编解码器本身可以是硬件与软件的任何组合形式，这样编解码器可以做到==对用户透明==，用户无需关注编解码器的实现细节问题。如果没有IL，那么不同的编解码厂商都需要按照自己的方式实现一套接口，并且各个厂商之间也是不通用的，这样会使得跨平台移植变得极其复杂。 DL 提供软件(如视频编解码器和3D引擎)和物理硬件(如DSP、CPUs、GPUs)之间的标准化接口，全方位包含了OpenMAX音频、视频以及图像处理功能（函数集合），这些功能可以由芯片厂商针对新的处理器进行实现和优化，然后编解码厂商在此基础上实现一些广泛的编解码功能： 音频信号处理：比如FFT（快速傅立叶变换）、滤波器等； 图像处理：比如色域转换（RGB、YUV等）； 视频处理：比如实现并且优化的 MPEG-4, H.264, MP3, AAC 和 JPEG； 组件 组件是OpenMAX IL的单元，每一个组件实现一种功能。 组成 配置结构体（Parameter/Configuration Set/Get）：用于用户代码直接与组件进行交互，包括组件属性设置获取、组件状态设置获取等。 Port口：负责记录与之建立隧道链接的组件的信息，数据交流必不可少。 Buffer管理：负责管理组件内部接收以及送出的数据流。 组件事件句柄（Component Event Handler）：负责组件向用户代码进行事件通知，类似于Linux内核的Input子系统事件。 命令序列：负责存储并处理来自于用户代码产生的命令，比如状态转换等。 IL Client IL层的客户端，组件的管理者，Client通过组件内部提供的相关回调函数来对组件进行管理，应用程序调用IL Client提供的接口来操作组件。 Tunneled 两个组件通过port进行相互链接，然后组件内部自行协调进行数据交流。整个链接过程是由组件的管理者连续调用两个组件的链接函数完成的，组件的链接函数里面会判断两个port是否适合链接，如果适合的话就将对方port以及COMP的句柄信息记录下来，存放到一个port结构体描述当中，这样的话两个组件就可以通过port来进行通信以及数据传输了。 "},"RTSP&RTP&RTCP/RTSP&RTP&RTCP.html":{"url":"RTSP&RTP&RTCP/RTSP&RTP&RTCP.html","title":"RTP & RTCP & RTSP","keywords":"","body":" 简介 RTSP（Real Time Streaming Protocol） RTP（Real-time Transport Protocol） RTCP（Real-time Transport Control Protocol） RTP 实时传输 RTP建立在UDP上 RTP是应用层的一部分 RTP的工作机制 RTP首部 RTCP RSTP RTSP&RTP&RTCP 简介 RTSP（Real Time Streaming Protocol） TCP/IP协议体系中的应用层协议，负责有效传输 RTSP位于RTP和RTCP之上，使用TCP或UDP完成数据传输 RTSP的客户端和服务器端都可以发出请求 RTP（Real-time Transport Protocol） 详细说明了在互联网上传递音频和视频的标准数据包格式 RTCP（Real-time Transport Control Protocol） RTP的姐妹协议，由于RTP只负责有序传输并不保证可靠传输，因此使用RTCP为正在提供的服务做质量反馈和同步 RTP 负责对流媒体数据进行封包并实现媒体流的实时传输，该协议提供的信息包括：时间戳（用于同步）、序列号（用于丢包和重排序检测）、以及负载格式（用于说明数据的编码格式）。 实时传输 TCP作为可靠传输协议，有对应的检测和重传机制确保数据能够正确送达目的地址，但是一旦发生数据丢失，数据流的传说会被迫暂停和延迟，这在实时传输中是不能容忍的。因此RTP基于UDP传输协议，其本身不提供可靠的传输机制或是流量控制或拥塞控制，它依靠RTCP提供这些服务。当发生数据丢失时，由上层决定重传机制（控制信息），例如I帧、P帧、B帧数据，在网络状况不佳时，如果丢失P帧或是B帧，可以不进行重传，由预测算法完成丢帧的补全（即使画面出现卡顿也优先保证实时性）。 RTP建立在UDP上 从上图可看出RTP被划分在传输层，它建立在UDP上。同UDP协议一样，为了实现其实时传输功能，RTP也有固定的封装形式。RTP用来为端到端的实时传输提供时间信息和流同步，但并不保证服务质量。服务质量由RTCP来提供。 RTP是应用层的一部分 从应用开发者的角度看，RTP 应当是应用层的一部分。在应用的发送端，开发者必须编写用 RTP 封装分组的程序代码，然后把 RTP 分组交给 UDP 插口接口。在接收端，RTP 分组通过 UDP 插口接口进入应用层后，还要利用开发者编写的程序代码从 RTP 分组中把应用数据块提取出来。 RTP的工作机制 当应用程序建立一个RTP会话时，应用程序将确定一对目的传输地址。目的传输地址由一个网络地址和一对端口组成IP地址：端口号，有两个端口：偶数端口给RTP包，奇数端口给RTCP包，使得RTP/RTCP数据能够正确发送。RTP数据发向偶数的UDP端口，而对应的控制信号RTCP数据发向相邻的奇数UDP端口（偶数的UDP端口＋1），这样就构成一个UDP端口对。 RTP分组只包含数据信息 RTCP分组包含控制信息 RTP首部 l V：RTP协议的版本号，占2位，当前协议版本号为2 l P：填充标志，占1位，如果P=1，则在该报文的尾部填充一个或多个额外的八位组，它们不是有效载荷的一部分 l X：扩展标志，占1位，如果X=1，则在RTP报头后跟有一个扩展报头 l CC：CSRC计数器，占4位，指示CSRC 标识符的个数，多于15个也只记15个 l M: 标记，占1位，不同的有效载荷有不同的含义，对于视频，标记一帧的结束；对于音频，标记会话的开始 l PT: 有效载荷类型，占7位，用于说明RTP报文中有效载荷的类型，如GSM音频、JPEM图像等 l 序列号：占16位，用于标识发送者所发送的RTP报文的序列号，每发送一个报文，序列号增1。接收者通过序列号来检测报文丢失情况，重新排序报文，恢复数据 l 时戳(Timestamp)：占32位，时戳反映了该RTP报文的第一个八位组的采样时刻。接收者使用时戳来计算延迟和延迟抖动，并进行同步控制 l 同步信源(SSRC)标识符：占32位，用于标识同步信源。该标识符是随机选择的（MD5随机算法），在同一个RTP会话中不能有相同的SSRC l 参与源(CSRC)标识符：0～15项，每项32比特，用来标志对一个RTP混合器产生的新包有贡献的所有RTP包的源。由混合器将这些有贡献的SSRC标识符插入表中。SSRC标识符都被列出来，以便接收端能正确指出交谈双方的身份 这里的同步信源是指产生媒体流的信源，它通过RTP报头中的一个32位数字SSRC标识符来标识，而不依赖于网络地址，接收者将根据SSRC标识符来区分不同的信源，进行RTP报文的分组。特约信源是指当混合器接收到一个或多个同步信源的RTP报文后，经过混合处理产生一个新的组合RTP报文，并把混合器作为组合RTP报文的SSRC，而将原来所有的SSRC都作为CSRC传送给接收者，使接收者知道组成组合报文的各个SSRC。 RTCP RTCP负责服务质量的监视与反馈、媒体间的同步，以及多播组中成员的标识。在RTP会话期 间，各参与者周期性地传送RTCP包。RTCP包中含有已发送的数据包的数量、丢失的数据包的数量等统计资料，因此，各参与者可以利用这些信息动态地改变传输速率，甚至改变有效载荷类型。RTP和RTCP配合使用，它们能以有效的反馈和最小的开销使传输效率最佳化，因而特别适合传送网上的实时数据。 QoS质量反馈 为每个RTP源传输一个固定的CNAME标识符 知晓成员数目，控制包的发送速率 传输最小连接控制信息 RTCP有如下五种分组类型： RSTP RTSP(Real-Time Stream Protocol)协议是一个基于文本的多媒体播放控制协议，属于应用层。RTSP以客户端方式工作，对流媒体提供播放、暂停、后退、前进等操作。该标准由IETF指定，对应的协议是RFC2326。RTSP作为一个应用层协议，提供了一个可供扩展的框架，使得流媒体的受控和点播变得可能，它主要用来控制具有实时特性的数据的发送，但其本身并不用于传送流媒体数据，而必须依赖下层传输协议(如RTP/RTCP)所提供的服务来完成流媒体数据的传送。RTSP负责定义具体的控制信息、操作方法、状态码，以及描述与RTP之间的交互操作。 "},"ion/ion.html":{"url":"ion/ion.html","title":"ION Buffer","keywords":"","body":" ION通过heap类型来代表不同的内存，不同的内存有不同的分配方式。 用户空间API ioctl() ion_alloc_fd() 后记 ION Memory Control ION子系统目的主要是通过在硬件设备和用户空间之间分配和共享内存，实现设备之间零拷贝共享内存。 零拷贝：CPU不执行拷贝数据从一个存储区域到另一个存储区域 ION是Google在Android 4.0 ICS中引入，用于改善对于当前不同平台的android设备，使用各种不同内存管理接口来管理相应内存的状况，ION将内存管理机制抽象成一系列通用的接口，可集中分配各类不同内存(ion_heap_type区分)。 ION的主要功能： 内存管理：提供通用（平台无关）的内存管理接口，通过heap管理各种类型的内存。 共享内存：可提供驱动之间、用户进程之间、内核空间和用户空间之间的共享内存。 ION通过heap类型来代表不同的内存，不同的内存有不同的分配方式。 // in ./src/system/core/libion/kernel-headers/linux/ion.h enum ion_heap_type { ION_HEAP_TYPE_SYSTEM, ION_HEAP_TYPE_SYSTEM_CONTIG, ION_HEAP_TYPE_CARVEOUT, ION_HEAP_TYPE_CHUNK, ION_HEAP_TYPE_DMA, ION_HEAP_TYPE_CUSTOM, ION_NUM_HEAPS = 16, }; 每个heap中可分配若干个buffer，每个client(ion_open()返回的fd)通过handle管理对应的buffer。每个buffer只能有一个handle对应，每个用户进程只能有一个client，每个client可能有多个handle(申请多块内存空间)。两个client通过文件描述符fd，通过映射方式，将相应内存映射，实现共享内存。 handle通过ion_alloc_fd()赋值，client通过handle来获取分配的ion内存的地址，目前来说并没有碰到过使用ION共享内存的情况，可能因为效率太低？有因为要使用C2D而去申请ion buffer的情况，除了因为C2D要求使用ion，还有为了减少I/O操作加速对图片读写速度的考量，因为通过ION_IOCRL_XXX申请到的空间都位于高速缓存中，CPU可以直接读取到，并且在用户进程中为了方便使用，通常会使用mmap()将ion buffer地址映射到用户空间。 // open /dev/ion static int ion_fd_get(void) { static int fd = -1; if (fd == -1) { fd = ion_open(); } return fd; } /* * @brief alloc ion buffer * @param ion_fd ion_user_handle_t * @param size ion buffer size * @param addr user_space addr */ static int alloc_ion_buffer(int *ion_fd, int size, void **addr) { int ret; if (!ion_fd || !addr || size 用户空间API 用户空间API通过ioctl直接与驱动交互。 // in .//src/system/core/libion/include/ion/ion.h int ion_open(); int ion_close(int fd); int ion_alloc(int fd, size_t len, size_t align, unsigned int heap_mask, unsigned int flags, ion_user_handle_t *handle); int ion_alloc_fd(int fd, size_t len, size_t align, unsigned int heap_mask, unsigned int flags, int *handle_fd); int ion_sync_fd(int fd, int handle_fd); int ion_free(int fd, ion_user_handle_t handle); int ion_map(int fd, ion_user_handle_t handle, size_t length, int prot, int flags, off_t offset, unsigned char **ptr, int *map_fd); int ion_share(int fd, ion_user_handle_t handle, int *share_fd); int ion_import(int fd, int share_fd, ion_user_handle_t *handle); ioctl() 用户空间API对应的ioctl()操作 // in ./src/system/core/libion/kernel-headers/linux/ion.h #define ION_IOC_ALLOC _IOWR(ION_IOC_MAGIC, 0, struct ion_allocation_data) #define ION_IOC_FREE _IOWR(ION_IOC_MAGIC, 1, struct ion_handle_data) #define ION_IOC_MAP _IOWR(ION_IOC_MAGIC, 2, struct ion_fd_data) #define ION_IOC_SHARE _IOWR(ION_IOC_MAGIC, 4, struct ion_fd_data) #define ION_IOC_IMPORT _IOWR(ION_IOC_MAGIC, 5, struct ion_fd_data) #define ION_IOC_SYNC _IOWR(ION_IOC_MAGIC, 7, struct ion_fd_data) #define ION_IOC_CUSTOM _IOWR(ION_IOC_MAGIC, 6, struct ion_custom_data) 具体的实现在ion-ioctl.c中。 ion_alloc_fd() // in ./src/system/core/libion/ion.c int ion_alloc_fd(int fd, size_t len, size_t align, unsigned int heap_mask, unsigned int flags, int* handle_fd) { ion_user_handle_t handle; int ret; if (!ion_is_legacy(fd)) return -EINVAL; ret = ion_alloc(fd, len, align, heap_mask, flags, &handle); if (ret ion_alloc_fd()所有的参数实际是调用ion_alloc()，填充ion_allocation_data结构体，并调用对应的ioctl（ION_IOC_ALLOC）操作，并返回一个handle给handle_fd。 // in ./src/system/core/libion/kernel-headers/linux/ion.h struct ion_allocation_data { size_t len; size_t align; unsigned int heap_id_mask; unsigned int flags; ion_user_handle_t handle; }; len：分配的大小。 align：对齐标志，通常为页对齐（4096） heap_mask：待分配所使用的所有heaps的掩码(用于区分heap类型，实际是1 flags：传给heap的标志（如：ION_FLAG_CACHED），ion系统使用低16位，高16位用于各自heap实现使用。 handle：ion buffer的句柄 原以为handle会作为ion_alloc_fd()的返回，但是查看ion_share()的源码，在ion_share()中会填充ion_fd_data结构体——进程共享内存所需的元数据，并且最终返回的是用于共享内存的文件描述符。 // in ./src/system/core/libion/kernel-headers/linux/ion.h /** * struct ion_fd_data - metadata passed to/from userspace for a handle/fd pair * @handle: a handle * @fd: a file descriptor representing that handle * * For ION_IOC_SHARE or ION_IOC_MAP userspace populates the handle field with * the handle returned from ion alloc, and the kernel returns the file * descriptor to share or map in the fd field. For ION_IOC_IMPORT, userspace * provides the file descriptor and the kernel returns the handle. */ struct ion_fd_data { ion_user_handle_t handle; int fd; } 后记 关于ION的概念就讲这么多，主要集中在应用上，再往下的内核空间API由于本人水平有限，涉及到更底层偏向于物理硬件的内存申请操作即使看过代码也无法能很好的描述其逻辑，而简单的讲解源码在我看来是没有必要的。 第一次运用ION是在多路视频应用中，使用了FFmpeg来解码视频，由于解码出的图片帧是YUV420 NV12，为了显示还需要进行色彩空间转换，如果使用常规色彩空间转换API(如OpenCV)，那么会耗费大量时间在读写和拷贝操作上，因此使用C2D库(依赖于ION)来完成色彩转换操作。在当时我以为ION是一块特殊设计(具有硬件加速功能)且实际存在的物理内存(类似于主存的边角料，但被保留)，因此我理解的是我的用户进程和该物理硬件之间存在内存共享。但是review代码之后，根据我的粗浅理解，这并不会用到ION内存共享的特性，只是因为ION申请到的buffer已经位于高速缓存中，提高了读写命中率，忙完手上这个AIDemo工程后会开始Camera相关的学习，也正是ION框架的应用所在，希望之后会有更好的理解。 "},"gitbook/gitbook_tutorial.html":{"url":"gitbook/gitbook_tutorial.html","title":"Gitbook","keywords":"","body":" Gitbook Install Usage Basic command Directory structure Gitbook-plugin Markdown FAQ Gitbook Tutorial Gitbook gitbook是一个基于Node.js的命令行工具。 Install # install node.js 10.23.1 and npm curl -sL https://deb.nodesource.com/setup_10.x | sudo -E bash - sudo apt-get install -y nodejs # check the node.js version nodejs -v # install gitbook sudo npm install -g gitbook-cli # check the gitbook version gitbook -V Usage Basic command 新建书籍，在目录中执行：gitbook init 构建预览html文件：gitbook build 开启服务在浏览其中预览：gitbook serve Directory structure After you init, you should get two .md file include README.md and SUMMARY.md, and in genaral, one gitbook will format like this: . ├── book.json ├── README.md ├── SUMMARY.md ├── chapter-1/ | ├── README.md | └── something.md └── chapter-2/ ├── README.md └── something.md book.json：主要用来放置配置信息，包括页面设置，插件等。 README.md：通常是gitbook的说明信息 SUMMARY.md：决定 GitBook 的章节目录，它通过 Markdown 中的列表语法来表示文件的父子关系，下面是一个简单的示例。 # SUMMARY.md * [Introduction](README.md) * [Part I](part1/README.md) * [Writing is nice](part1/writing.md) * [GitBook is nice](part1/gitbook.md) * [Part II](part2/README.md) * [We love feedback](part2/feedback_please.md) * [Better tools for authors](part2/better_tools.md) 这个配置对应的目录结构如下所示: Gitbook-plugin GitBook 有 插件官网，默认带有 5 个插件，highlight、search、sharing、font-settings、livereload。修改gitbook-plugin只需要修改项目目录下的book.json即可，例如： { \"plugins\": [ \"toc\", \"hide-element\", \"page-treeview\", \"simple-page-toc\" ], \"pluginsConfig\":{ \"hide-element\": { \"elements\": [\".gitbook-link\"] }, \"page-treeview\": { \"copyright\": \"Copyright &#169; aleen42\", \"minHeaderCount\": \"2\", \"minHeaderDeep\": \"6\" } } } toc为目录插件 hide-element为隐藏组件插件，用于隐藏gitbook Copyright page-treeview目录插件 simple-page-toc简易导航插件 gitbook install安装新插件 Markdown Gitbook文档使用.md格式文档，关于Markdown的语法可以查看Markdown教程。 Markdown编辑器可以使用Typora. FAQ 禁用page-treeview plugin copyright Copyright信息为plugin作者内嵌信息，需要修改plugin脚本源码，删除关于copyright相关定义与显示。 # 当前项目目录 vim ./node_modules/gitbook-plugin-page-treeview/lib/index.js # 查找Copyright相关定义，删去即可 # 注意：每次执行gitbook install之后都要修改 gitbook build生成的.html单击不跳转： 点击事件被js代码禁用导致新版本的gitbook不支持单击事件，所以点击没有反应，但是如果右键，在新窗口/新标签页打开的话是可以跳转的，解决办法如下： # 当前项目目录 vim ./_book/gitbok/theme.js # 查找 “if(m)for(n.handler&&“ # 将判断条件m改为false即可 # 注意：每次gitbook build之后都需要修改 gitbook部署 # 将远端仓库克隆到本地 # 然后将本地修改上传，并使用Github Pages来解析 git push -u origin master git subtree push --prefix=_book origin gh-pages "},"getopt/getopt_long.html":{"url":"getopt/getopt_long.html","title":"getopt_long()","keywords":"","body":"Linux命令行解析函数getopt_long() Linux环境下大多数程序被编译成带参数运行的可执行程序，C语言提供了几个命令行参数解析函数来辅助完成工作。 getopt_long() getopt()只能处理短选项，而getopt_long()由于长选项结构体option返回的原因可以同时处理长选项和短选项。 #include extern char *optarg; extern int optind, opterr, optopt; #include int getopt(int argc, char * const argv[],const char *optstring); int getopt_long(int argc, char * const argv[], const char *optstring, const struct option *longopts, int *longindex); int getopt_long_only(int argc, char * const argv[], const char *optstring, const struct option *longopts, int *longindex); argc：参数个数 argv：参数内容 optstring：表示短选项字符串。 形式如a:b::cd:，分别表示程序支持的命令行短选项有-a、-b、-c、-d，冒号含义如下： 只有一个字符，不带冒号——只表示选项， 如：-c 一个字符，后接一个冒号——表示选项后面带一个参数，如：-a 100 一个字符，后接两个冒号——表示选项后面带一个可选参数，即参数可有可无， 如果带参数，则选项与参数直接不能有空格，如：-b10 longopts：长选项结构体 struct option { const char *name; int has_arg; int *flag; int val; }; (1)name：表示选项的名称,比如daemon,dir,out等 (2)has_arg：表示选项后面是否携带参数，该参数有三个不同值，如下： no_argument(或者是0)时 ——参数后面不跟参数值 required_argument(或者是1)时 ——参数输入格式为：--参数 值 或者 --参数=值 optional_argument(或者是2)时 ——参数输入格式只能为：--参数=值 (3)flag： 如果参数为空NULL，那么当选中某个长选项的时候，getopt_long将返回val值（这种情况下val通常被定义为短选项值） 如果参数不为空，那么当选中某个长选项的时候，getopt_long将返回0，并且将flag指针参数指向val值。 (4)val：表示指定函数找到该选项时的返回值，或者当flag非空时指定flag指向的数据的值val longindex：当找到对应选项时返回的是该选项在longopts结构体数组中的下标 全局变量： optarg：当前选项对应的参数值 optind：下一个将被处理到的参数在argv中的下标值 opterr：getopt()，getopt_long()函数错误信息 optopt：最后一个未知选项 返回值： 短选项找到，返回短选项对应的字符 长选项找到，flag为NULL则返回val，flag不为NULL则返回0 未找到返回-1 #include #include #include int main() { while(1) { int c; struct option long_opts[] { {\"input_img\", required_argument, NULL, 'i'}, {\"input_fmt\", required_argument, NULL, 's'}, {\"output_img\", required_argument, NULL, 'o'}, {\"output_fmt\", required_argument, NULL, 'f'}, {\"width\", required_argument, NULL, 'w'}, {\"height\", required_argument, NULL, 'd'}, {\"test\", required_argument, &lopt, 1}, {\"help\", no_argument, NULL, 'h'}, {NULL , 0, NULL, 0} // option结构体数组结束标志，不可省略 }; c = getopt_long(argc, argv, \"i:s:o:f:w:d:h\", long_opts, &option_index); if (c == -1) break; switch (c) { case 'i': image.path = optarg; break; case 's': image.src_fmt = (pix_fmt)atoi(optarg); break; case 'o': output_path = optarg; break; case 'f': image.dst_fmt = (pix_fmt)atoi(optarg); break; case 'w': image.width = atoi(optarg); break; case 'd': image.height = atoi(optarg); break; case 'h': default: // usage(); exit(-1); } } return 0; } "}}